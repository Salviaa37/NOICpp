---
source: https://oi-wiki.org/basic/
---

# 贪心
贪心算法（Greedy Algorithm）：一种在每次决策时，总是采取在当前状态下的最好选择，从而希望导致结果是最好或最优的算法。

## 核心思想
贪心算法是一种改进的分步解决算法，其核心思想是：
- 将求解过程分成「若干个步骤」，然后根据题意选择一种「度量标准」；
- 每个步骤都根据度量标准，选取当前状态下「最好 / 最优选择（局部最优解）」，叫做“贪心原则”。
- 如此不断做选择，==期望最后得出的结果==也是「最好 / 最优结果（全局最优解）」。

换句话说，贪心算法不从整体最优上加以考虑，而是一步一步进行，==每一步只以当前情况为基础==，根据某个优化测度做出局部最优选择，从而省去了为找到最优解要穷举所有可能所必须耗费的大量时间。

## 例：凑出指定金额
给定 $n$ 种硬币，第 $i$ 种硬币的面值为 $coins[i−1]$ ，目标金额为 $amt$ ，每种硬币可以重复选取，问==能够凑出目标金额的最少硬币数量==。如果无法凑出目标金额，则返回 $−1$ 。

我们使用贪心的方式：本题采取的贪心策略如图 所示。给定目标金额，我们贪心地选择不大于且最接近它的硬币，不断循环该步骤，直至凑出目标金额为止。
![[Pasted image 20250726233521.png]]
```cpp
/* 零钱兑换：贪心 */
int coinChangeGreedy(vector<int> &coins, int amt) {
    // 假设 coins 列表有序
    int i = coins.size() - 1;
    int count = 0;
    // 循环进行贪心选择，直到无剩余金额
    while (amt > 0) {
        // 找到小于且最接近剩余金额的硬币
        while (i > 0 && coins[i] > amt) {
            i--;
        }
        // 选择 coins[i]
        amt -= coins[i];
        count++;
    }
    // 若未找到可行方案，则返回 -1
    return amt == 0 ? count : -1;
}
```

## 使用条件
一般情况下，贪心算法的适用情况分以下两种。

可以保证找到最优解：贪心算法在这种情况下往往是最优选择，因为它往往==比回溯、动态规划==更高效。

可以找到近似最优解：贪心算法在这种情况下也是可用的。对于很多复杂问题来说，寻找全局最优解非常困难，能以较高效率找到次优解也是非常不错的。

### 与动态规划的区别
贪心算法与动态规划的不同在于它对每个子问题的解决方案都做出选择，不能回退。动态规划则会保存以前的运算结果，并根据以前的结果对当前进行选择，有回退功能。
相较于动态规划，贪心算法的使用条件更加苛刻，其主要关注问题的两个性质。

1 贪心选择性质：只有==当局部最优选择始终可以导致全局最优解时==，贪心算法才能保证得到最优解。
2 最优子结构：原问题的最优解包含子问题的最优解。
最优子结构已经在“动态规划”章节中介绍过，这里不再赘述。值得注意的是，一些问题的最优子结构并不明显，但仍然可使用贪心算法解决。

我们主要探究贪心选择性质的判断方法。虽然它的描述看上去比较简单，但实际上对于许多问题，证明贪心选择性质并非易事。

例如零钱兑换问题，我们虽然能够容易地举出反例，对贪心选择性质进行证伪，但证实的难度较大。如果问：满足什么条件的硬币组合可以使用贪心算法求解？我们往往只能凭借直觉或举例子来给出一个模棱两可的答案，而难以给出严谨的数学证明。

## 应用场景
### 常见题型
在提高组难度以下的题目中，最常见的贪心有两种。

「我们将 XXX 按照某某顺序排序，然后按某种顺序（例如从小到大）选择。」。
「我们每次都取 XXX 中最大/小的东西，并更新 XXX。」（有时「XXX 中最大/小的东西」可以优化，比如用优先队列维护）。

二者的区别在于一种是离线的，先处理后选择；一种是在线的，边处理边选择。

贪心算法常常应用在满足贪心选择性质和最优子结构的优化问题中，以下列举了一些典型的贪心算法问题。

- 硬币找零问题：在某些硬币组合下，贪心算法总是可以得到最优解。
- 区间调度问题：假设你有一些任务，每个任务在一段时间内进行，你的目标是完成尽可能多的任务。如果每次都选择结束时间最早的任务，那么贪心算法就可以得到最优解。
- 分数背包问题：给定一组物品和一个载重量，你的目标是选择一组物品，使得总重量不超过载重量，且总价值最大。如果每次都选择性价比最高（价值 / 重量）的物品，那么贪心算法在一些情况下可以得到最优解。
- 股票买卖问题：给定一组股票的历史价格，你可以进行多次买卖，但如果你已经持有股票，那么在卖出之前不能再买，目标是获取最大利润。
- 哈夫曼编码：霍夫曼编码是一种用于无损数据压缩的贪心算法。通过构建霍夫曼树，每次选择出现频率最低的两个节点合并，最后得到的霍夫曼树的带权路径长度（编码长度）最小。
- Dijkstra 算法：它是一种解决给定源顶点到其余各顶点的最短路径问题的贪心算法。

### 例题1
你是一位家长，想要给你的孩子们一些小饼干。但是，每个孩子最多只能给一块饼干。

对每个孩子 `i`，都有一个胃口值 `g[i]`，这是能让孩子们满足胃口的饼干的最小尺寸；并且每块饼干 `j`，都有一个尺寸 `s[j]` 。如果 `s[j] >= g[i]`，我们可以将这个饼干 `j` 分配给孩子 `i` ，这个孩子会得到满足。你的目标是满足尽可能多的孩子，并输出这个最大数值。
示例 1:
输入: `g = [1,2,3], s = [1,1]`
输出: `1`
解释: 你有三个孩子和两块小饼干，3 个孩子的胃口值分别是：1,2,3。
虽然你有两块小饼干，由于他们的尺寸都是 1，你只能让胃口值是 1 的孩子满足。所以你应该输出 1。

示例 2:
输入: `g = [1,2], s = [1,2,3]`
输出: `2`
解释: 你有两个孩子和三块小饼干，2 个孩子的胃口值分别是 1,2。
你拥有的饼干数量和尺寸都足以让所有孩子满足。所以你应该输出 2。

我们应该怎样发饼干？如果先从大饼干开始发，势必会饿到胃口大的孩子，所以饼干应该从小开始发，直到找到能满足当前小孩的胃口，就给他饼干。
代码：
```cpp
int findContentChildren(vector<int>& g, vector<int>& s) {
	sort(g.begin(), g.end());
	sort(s.begin(), s.end());
	
	int count = 0;
	for (int i = 0, j = 0; i < g.size() && j < s.size(); i++, j++) {
		while (j < n && g[i] > s[j]) {
			j++;
		}
		if (j < n) {
			count++;
		}
	}
	return count;
}

```


# 递推
## 核心思想

## 解题步骤

## 应用场景

# 递归
递归（Recursion）：指的是一种通过重复将原问题分解为同类的子问题而解决的方法。在绝大数编程语言中，可以通过在函数中再次调用函数自身的方式来实现递归。
递归特点是==函数或过程==调用自己本身，其中直接调用自己称为直接递归，而
将A调用B,B调用A的递归叫做间接递归。

根据阶乘计算方法的数学定义，我们可以使用调用函数自身的方式来实现阶乘函数 $fact(n)$，其实现代码可以写作：
```cpp
int fact(n){
	if(n == 0){
		return 1;
	}
	return n * fact(n-1);
}
```
递归的调用过程如下：
```cpp
fact(6)
= 6 * fact(5)
= 6 * (5 * fact(4))
= 6 * (5 * (4 * fact(3)))
= 6 * (5 * (4 * (3 * fact(2))))
= 6 * (5 * (4 * (3 * (2 * fact(1)))))
= 6 * (5 * (4 * (3 * (2 * (1 * fact(0))))))
= 6 * (5 * (4 * (3 * (2 * (1 * 1)))))
= 6 * (5 * (4 * (3 * (2 * 1))))
= 6 * (5 * (4 * (3 * 2)))
= 6 * (5 * (4 * 6))
= 6 * (5 * 24)
= 6 * 120
= 720
```
根据上面的描述，我们可以把阶乘函数的递归计算过程分为两个部分：

1. 先逐层向下调用自身，直到达到结束条件（即 `n==0`）。
2. 然后再向上逐层返回结果，直到返回原问题的解（即返回 `fact(6)==720`）。
这两个部分也可以叫做「==递推过程==」和「==回归过程==」，如下面两幅图所示：
递推过程：![[Pasted image 20250628135030.png]]
回归过程：![[Pasted image 20250628135100.png]]
如上面所说，我们可以把「递归」分为两个部分：「递推过程」和「回归过程」。

- 递推过程：指的是将原问题一层一层地分解为与==原问题形式相同、规模更小的子问题==，直到达到结束条件时停止，此时返回最底层子问题的解。
- 回归过程：指的是从最底层子问题的解开始，逆向逐一回归，==最终达到递推开始时的原问题==，返回原问题的解。

「递推过程」和「回归过程」是递归算法的精髓。从这个角度来理解递归，递归的基本思想就是： 把规模大的问题不断分解为子问题来解决。

同时，因为解决原问题和不同规模的小问题往往使用的是相同的方法，所以就产生了函数调用函数自身的情况，这也是递归的定义所在。

## 递归步骤
上面我们提到，递归的基本思想就是： 把规模大的问题不断分解为子问题来解决。 那么，在写递归的时候，我们可以按照这个思想来书写递归，具体步骤如下：

1. 写出递推公式：找到将原问题分解为子问题的规律，并且根据规律写出==递推公式==。
2. 明确终止条件：推敲出递归的==终止条件==，以及递归终止时的处理方法。
3. 将递推公式和终止条件翻译成代码：
    1. 定义递归函数（明确函数意义、传入参数、返回结果等）。
    2. 书写递归主体（提取重复的逻辑，缩小问题规模）。
    3. 明确递归终止条件（给出递归终止条件，以及递归终止时的处理方法）。

伪代码如下：
```cpp
type_name recursion(大规模问题){
	if(递归终止条件){
		递归终止时的处理办法;
	}
	return recursion(小规模问题);
}
```

# 回溯（Backtracking）
回溯算法（backtracking algorithm）是一种通过穷举来解决问题的方法，它的核心思想是从一个初始状态出发，暴力搜索所有可能的解决方案，当遇到正确的解则将其记录，直到找到解或者尝试了所有可能的选择都无法找到解为止。

回溯算法通常采用“==深度优先搜索==”来遍历解空间。在“二叉树”章节中，我们提到==前序、中序和后序遍历都属于深度优先搜索==。接下来，我们利用前序遍历构造一个回溯问题，逐步了解回溯算法的工作原理。

例题一
给定一棵二叉树，搜索并记录所有值为 $7$ 的节点，请返回节点列表。

对于此题，我们前序遍历这棵树，并判断当前节点的值是否为 $7$ ，若是，则将该节点的值加入结果列表 `res` 之中。相关过程实现如图 13-1 和以下代码所示：

```python
# preorder_traversal_i_compact.py 
def pre_order(root: TreeNode):
    """前序遍历：例题一"""
    if root is None:
        return
    if root.val == 7:
        # 记录解
        res.append(root)
    pre_order(root.left)
    pre_order(root.right)
```

```cpp
// preorder_traversal_i_compact.cpp/* 前序遍历：例题一 */
void preOrder(TreeNode *root) {
    if (root == nullptr) {
        return;
    }
    if (root->val == 7) {
        // 记录解
        res.push_back(root);
    }
    preOrder(root->left);
    preOrder(root->right);
}
```
![[Pasted image 20250818130933.png]]
## 尝试与回退

**之所以称之为回溯算法，是因为该算法在搜索解空间时会采用“尝试”与“回退”的策略** 。当算法在搜索过程中遇到某个状态无法继续前进或无法得到满足条件的解时，它会撤销上一步的选择，退回到之前的状态，并尝试其他可能的选择。

对于例题一，访问每个节点都代表一次“尝试”，而越过叶节点或返回父节点的 `return` 则表示“回退”。

值得说明的是， **回退并不仅仅包括函数返回** 。为解释这一点，我们对例题一稍作拓展。

例题二

在二叉树中搜索所有值为 $7$ 的节点， **请返回根节点到这些节点的路径** 。

在例题一代码的基础上，我们需要借助一个列表 `path` 记录访问过的节点路径。当访问到值为 $7$ 的节点时，则复制 `path` 并添加进结果列表 `res` 。遍历完成后， `res` 中保存的就是所有的解。代码如下所示：

```cpp
//preorder_traversal_ii_compact.cpp/* 前序遍历：例题二 */
void preOrder(TreeNode *root) {
    if (root == nullptr) {
        return;
    }
    // 尝试
    path.push_back(root);
    if (root->val == 7) {
        // 记录解
        res.push_back(path);
    }
    preOrder(root->left);
    preOrder(root->right);
    // 回退
    path.pop_back();
}
```

##   剪枝(Pruning)

复杂的回溯问题通常包含一个或多个约束条件，**约束条件通常可用于“剪枝”**。

例题三
在二叉树中搜索所有值为 $7$ 的节点，请返回根节点到这些节点的路径，**并要求路径中不包含值为 $3$ 的节点**。

为了满足以上约束条件，**我们需要添加剪枝操作**：在搜索过程中，若遇到值为 $3$ 的节点，则提前返回，不再继续搜索。代码如下所示：
```cpp
/* 前序遍历：例题三 */
void preOrder(TreeNode *root) {
    // 剪枝
    if (root == nullptr || root->val == 3) {
        return;
    }
    // 尝试
    path.push_back(root);
    if (root->val == 7) {
        // 记录解
        res.push_back(path);
    }
    preOrder(root->left);
    preOrder(root->right);
    // 回退
    path.pop_back();
}
```

![[Pasted image 20250818131317.png]]



## 代码框架
接下来，我们尝试将回溯的“尝试、回退、剪枝”的主体框架提炼出来，提升代码的通用性。

在以下框架代码中，`state` 表示问题的当前状态，`choices` 表示当前状态下可以做出的选择：
```cpp
/* 回溯算法框架 */
void backtrack(State *state, vector<Choice *> &choices, vector<State *> &res) {
    // 判断是否为解
    if (isSolution(state)) {
        // 记录解
        recordSolution(state, res);
        // 不再继续搜索
        return;
    }
    // 遍历所有选择
    for (Choice choice : choices) {
        // 剪枝：判断选择是否合法
        if (isValid(state, choice)) {
            // 尝试：做出选择，更新状态
            makeChoice(state, choice);
            backtrack(state, choices, res);
            // 回退：撤销选择，恢复到之前的状态
            undoChoice(state, choice);
        }
    }
}
```

## 优点与局限性
回溯算法本质上是一种==深度优先搜索算法==，它尝试所有可能的解决方案直到找到满足条件的解。这种方法的优点在于能够找到所有可能的解决方案，而且在合理的剪枝操作下，具有很高的效率。

然而，在处理大规模或者复杂问题时，**回溯算法的运行效率可能难以接受**。

- **时间**：回溯算法通常需要遍历状态空间的所有可能，时间复杂度可以达到指数阶或阶乘阶。
- **空间**：在递归调用中需要保存当前的状态（例如路径、用于剪枝的辅助变量等），当深度很大时，空间需求可能会变得很大。

即便如此，回溯算法仍然是某些==搜索问题==和==约束满足问题==的最佳解决方案。对于这些问题，由于无法预测哪些选择可生成有效的解，因此我们必须对所有可能的选择进行遍历。在这种情况下，**关键是如何优化效率**，常见的效率优化方法有两种。

- **剪枝**：==避免搜索那些肯定不会产生解的路径==，从而节省时间和空间。
- **启发式搜索**：==在搜索过程中引入一些策略或者估计值==，从而优先搜索最有可能产生有效解的路径。







# 分治 & 二分

归并排序
```cpp

// 归并操作
void merge(int a[], size_t alen, int b[], size_t blen){
	size_t i=0,j=0,k=0;
	while(i < alen && j < blen){
		if(b[j] < a[i]){
			c[k] = b[j];
			++j;
		} 
		else{
			c[k] = a[i];
			++i;
		}
		++k;
	}
	for(;i<alen;++i,++k) c[k] = a[i];
	for(;j<blen;++j,++k) c[k] = b[j];
}

// 排序操作
void merge_sort(int a[], int l, int r){
	if(r - l <= 1) return;
	int mid = l + (r - l) >> 1;
	merge_sort(a, l , mid); // [l,mid)
	merge_sort(a, mid, r);  // [mid,r)
	int temp[1000] ={ };
	merge( a+l, )
}
```

## 分治法

## 二分查找
二分查找（英语：binary search），也称折半搜索（英语：half-interval search）、对数搜索（英语：logarithmic search），是用来在一个有序数组中查找某一元素的算法。

### 过程

以在一个升序数组中查找一个数为例。

它每次考察数组当前部分的中间元素，如果中间元素刚好是要找的，就结束搜索过程；如果中间元素小于所查找的值，那么左侧的只会更小，不会有所查找的元素，只需到右侧查找；如果中间元素大于所查找的值同理，只需到左侧查找。

### 性质

#### 时间复杂度

二分查找的最优时间复杂度为 $O(1)$ 。正好在中间，1次就查到了。
二分查找的平均时间复杂度和最坏时间复杂度均为 $O(log⁡n)$ 。因为在二分搜索过程中，算法每次都把查询的区间减半，所以对于一个长度为 $n$ 的数组，至多会进行 $O(log⁡n)$ 次查找。

#### 空间复杂度

迭代版本的二分查找的空间复杂度为 $O(1)$ 。
递归（无尾调用消除）版本的二分查找的空间复杂度为 $O(log⁡n)$ 。

### 实现

```cpp
int binary_search(int start, int end, int key) {
  int ret = -1;  // 未搜索到数据返回-1下标
  int mid;
  while (start <= end) {
    mid = start + ((end - start) >> 1);  // 直接平均可能会溢出，所以用这个算法
    if (arr[mid] < key)
      start = mid + 1;
    else if (arr[mid] > key)
      end = mid - 1;
    else {  // 最后检测相等是因为多数搜索情况不是大于就是小于
      ret = mid;
      break;
    }
  }
  return ret;  // 单一出口
}
```

> Note：参考 [编译优化 #位运算代替乘法](https://oi-wiki.org/lang/optimizations/#%E4%BD%8D%E8%BF%90%E7%AE%97%E4%BB%A3%E6%9B%BF%E4%B9%98%E6%B3%95) ，对于 $n$ 是有符号数的情况，当你可以保证 $n≥0$ 时， `n >> 1` 比 `n / 2` 指令数更少。

### 最大值最小化

注意，这里的有序是广义的有序，如果一个数组中的左侧或者右侧都满足某一种条件，而另一侧都不满足这种条件，也可以看作是一种有序（如果把满足条件看做 $1$ ，不满足看做 $0$ ，至少对于这个条件的这一维度是有序的）。换言之，二分搜索法可以用来查找满足某种条件的最大（最小）的值。

要求满足某种条件的最大值的最小可能情况（最大值最小化），首先的想法是从小到大枚举这个作为答案的「最大值」，然后去判断是否合法。若答案单调，就可以使用二分搜索法来更快地找到答案。因此，要想使用二分搜索法来解这种「最大值最小化」的题目，需要满足以下三个条件：

1. 答案在一个固定区间内；
2. 可能查找一个符合条件的值不是很容易，但是要求能比较容易地判断某个值是否是符合条件的；
3. 可行解对于区间满足一定的单调性。换言之，如果 $x$ 是符合条件的，那么有 $x+1$ 或者 $x−1$ 也符合条件。（这样下来就满足了上面提到的单调性）

当然，最小值最大化是同理的。




# 倍增
### 核心思想
倍增法（英语：Binary Lifting），顾名思义就是「成倍增长」。
可以理解为“二进制分解+动态规划”的方法，用来快速解决“多次操作”的问题。
我们在进行递推时，如果状态空间很大，通常的线性递推无法满足时间与空间复杂度的要求，那么我们可以通过成倍增长的方式，只递推状态空间中在 k 的整数次幂位置上的值作为代表。
核心思想是：
- 如果我们能快速知道 一步操作的结果，那么我们可以通过成倍增长的方式，预先计算出 走 2 步、走 4 步、走 8 步……的结果。
- 当我们需要走 n 步时，只要把 n 用二进制拆分，例如 ，$n = 15 = 8 +4 +2 +1$，再把这些分解的结果拼起来，就能快速得到答案。

这样时间复杂度就从$O(n)$下降到了$O(\log n)$。

倍增法利用了唯一分解定理「任意整数可以表示成若干个 k 的次幂项的和」这一性质。
通常情况下对 n 使用 2进制拆分，具体操作是左移。


## 应用

### 快速幂

给定三个整数 a, b, m，计算 $a^b \mod m$。

输入
```
2 10 1000
```
输出
```
1024
```

解析
普通做法是把 a 连续乘 b 次，时间复杂度$O(b)$，这样做会超时。

倍增法
把 b 写成2进制，比如 $11 = 1011 =  8 + 2 + 1$；
也就是 $a^b = a^8 * a^2 * a^1$ ；
每次取 $b$ 的最右端， 如果是$1$ ，结果乘上$a$；
a 倍增， b左移一位，移除当前运算位。

```cpp
#include<iostream>
using namespace std;

typedef long long ll;

ll quickpow(ll a, ll b, ll mod){
    // 
    ll  res = 1 % mod;
    a % mod;

    while(b > 0){ 
        if(b & 1) res = res * a % mod; // 如果当前位置是1
        a = a * a % mod; // a翻倍
        b >>= 1;  // b左移，移除当前运算的位
    }
    return res;
}

int main(){
    ll a, b, m;
    cin >> a >> b >> m;
    cout << quickpow(a,b,m);
    return 0;
}

```

### 树上倍增求 LCA
在一棵树上，每个节点有一个亲节点，问“从节点 x 开始，走k步祖先后到达哪里”？
参见： [最近公共祖先](https://oi-wiki.org/graph/lca/)
最近公共祖先简称 LCA（Lowest Common Ancestor）。两个节点的最近公共祖先，就是这两个点的公共祖先里面，离根最远的那个。 为了方便，我们记某点集 $S = { v_{1} , v_{2} , ...  v_{n} }$ 的最近公共祖先为 $\text{LCA} \left(\right. v_{1} , v_{2} , \ldots , v_{n} \left.\right)$ 或 $\text{LCA} \left(\right. S \left.\right)$。

解析
- 预处理 `an[x][j]`，表示从节点x 出发，走$2^j$步到达的祖先位置。
- 查询时，把 k 按照二进制拆分，比如 $k = 13 = 8+4+1$，应该跳`an[x][3] ->fa[x][2] ->fa[x][0]`。

```cpp
void dfs(int now, int parent){
	dep[now] = dep[father] + 1;
	an[now][0] = father;
	for(int i = 1; )
}
```


### RMQ 问题

参见： [RMQ 专题](https://oi-wiki.org/topic/rmq/)

RMQ 是 Range Maximum/Minimum Query 的缩写，表示区间最大（最小）值。使用倍增思想解决 RMQ 问题的方法是 [ST 表](https://oi-wiki.org/ds/sparse-table/) 。
静态区间最值问题，可以用倍增法的“稀疏表”解决。

## 例题

 题 1
如何用尽可能少的砝码称量出 $[0,31]$ 之间的所有重量？（只能在天平的一端放砝码）

解题思路
答案是使用 1 2 4 8 16 这五个砝码，可以称量出 $[0,31]$ 之间的所有重量。同样，如果要称量 $[0,127]$ 之间的所有重量，可以使用 1 2 4 8 16 32 64 这七个砝码。每次我们都选择 2 的整次幂作砝码的重量，就可以使用极少的砝码个数量出任意我们所需要的重量。

为什么说是极少呢？因为如果我们要量出 $[0,1023]$ 之间的所有重量，只需要 10 个砝码，需要量出 $[0,1048575]$ 之间的所有重量，只需要 20 个。如果我们的目标重量翻倍，砝码个数只需要增加 1。这叫「对数级」的增长速度，因为砝码的所需个数与目标重量的范围的对数成正比。

 题 2
给出一个长度为 $n$ 的环和一个常数 $k$ ，每次会从第 $i$ 个点跳到第 $(i+k)modn+1$ 个点，总共跳了 $m$ 次。每个点都有一个权值，记为 $ai$ ，求 $m$ 次跳跃的起点的权值之和对 $109+7$ 取模的结果。

数据范围： $1≤n≤106$ ， $1≤m≤1018$ ， $1≤k≤n$ ， $0≤ai≤109$ 。

解题思路

这里显然不能暴力模拟跳 $m$ 次。因为 $m$ 最大可到 $1018$ 级别，如果暴力模拟的话，时间承受不住。

所以就需要进行一些预处理，提前整合一些信息，以便于在查询的时候更快得出结果。如果记录下来每一个可能的跳跃次数的结果的话，不论是时间还是空间都难以承受。

那么应该如何预处理呢？看看第一道例题。有思路了吗？

回到本题。我们要预处理一些信息，然后用预处理的信息尽量快的整合出答案。同时预处理的信息也不能太多。所以可以预处理出以 2 的整次幂为单位的信息，这样的话在预处理的时候只需要处理少量信息，在整合的时候也不需要大费周章。

在这题上，就是我们预处理出从每个点开始跳 1、2、4、8 等等步之后的结果（所处点和点权和），然后如果要跳 13 步，只需要跳 1+4+8 步就好了。也就是说先在起始点跳 1 步，然后再在跳了之后的终点跳 4 步，再接着跳 8 步，同时统计一下预先处理好的点权和，就可以知道跳 13 步的点权和了。

对于每一个点开始的 $2i$ 步，记录一个 `go[i][x]` 表示第 $x$ 个点跳 $2i$ 步之后的终点，而 `sum[i][x]` 表示第 $x$ 个点跳 $2i$ 步之后能获得的点权和。预处理的时候，开两重循环，对于跳 $2i$ 步的信息，我们可以看作是先跳了 $2i−1$ 步，再跳 $2i−1$ 步，因为显然有 $2i−1+2i−1=2i$ 。即我们有 `sum[i][x] = sum[i-1][x]+sum[i-1][go[i-1][x]]` ，且 `go[i][x] = go[i-1][go[i-1][x]]` 。

当然还有一些实现细节需要注意。为了保证统计的时候不重不漏，我们一般预处理出「左闭右开」的点权和。亦即，对于跳 1 步的情况，我们只记录该点的点权和；对于跳 2 步的情况，我们只记录该点及其下一个点的点权和。相当于总是不将终点的点权和计入 sum。这样在预处理的时候，只需要将两部分的点权和直接相加就可以了，不需要担心第一段的终点和第二段的起点会被重复计算。

这题的 $m≤1018$ ，虽然看似恐怖，但是实际上只需要预处理出 $65$ 以内的 $i$ ，就可以轻松解决，比起暴力枚举快了很多。用行话讲，这个做法的 [时间复杂度](https://oi-wiki.org/basic/complexity/) 是预处理 $Θ(nlog⁡m)$ ，查询每次 $Θ(log⁡m)$ 。

参考代码
```cpp
#include <cstdio>
using namespace std;

constexpr int mod = 1000000007;

int modadd(int a, int b) {
  if (a + b >= mod) return a + b - mod;  // 减法代替取模，加快运算
  return a + b;
}

int vi[1000005];

int go[75][1000005];  // 将数组稍微开大以避免越界，小的一维尽量定义在前面
int sum[75][1000005];

int main() {
  int n, k;
  scanf("%d%d", &n, &k);
  for (int i = 1; i <= n; ++i) {
    scanf("%d", vi + i);
  }

  for (int i = 1; i <= n; ++i) {
    go[0][i] = (i + k) % n + 1;
    sum[0][i] = vi[i];
  }

  int logn = 31 - __builtin_clz(n);  // 一个快捷的取对数的方法
  for (int i = 1; i <= logn; ++i) {
    for (int j = 1; j <= n; ++j) {
      go[i][j] = go[i - 1][go[i - 1][j]];
      sum[i][j] = modadd(sum[i - 1][j], sum[i - 1][go[i - 1][j]]);
    }
  }

  long long m;
  scanf("%lld", &m);

  int ans = 0;
  int curx = 1;
  for (int i = 0; m; ++i) {
    if (m & (1ll << i)) {  // 参见位运算的相关内容，意为 m 的第 i 位是否为 1
      ans = modadd(ans, sum[i][curx]);
      curx = go[i][curx];
      m ^= 1ll << i;  // 将第 i 位置零
    }
  }

  printf("%d\n", ans);
}
```
